{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction About LCLS is in need of various tools to support high level application development using python. This is an effort to locate a single repo that can be referenced for developemnt. lcls-tools Python tools for LCLS: * Device API (profile monitors, stoppers, magnets, etc...) * SLAC Logger * Custom Math Tools * Image Processing Tools * Beam calculations (emittance, solenoid alignment corrections, etc...) Rules of contribution (and python coding in general) Make your code readable (I like good one liners as much as the next person, but pulling apart syntax can be painful) Add comments whenever possible Try your best to adhere to style guidelines set forth in PEP8 Try to be idiomatic , there is a reason people spent time writing these guides. People are sick of seeing a simple operation being done a million different ways and having to parse out what insanity was behind some lines of code. Add tests (unittest is used currently, please use unit tests at a bare minimum) Focus on extensibility (don't shove a bunch of modules/classes into one file or directory and make them reference each other if you can avoid it) Try to understand the purpose of each tool and do not overcomplicate with business logic that can live in an application. These should be small and useful tools/apis with well understood and firm contracts between the api and the user Bonus: If you do all of the above in general, you will be a much better coder Why Python2.7 Unfortunately, the control system LCLS uses has Python27 as a default. That means these tools need to be compatible. This is a compliation of code written by different people so it's not entirely uniform, but I believe an upgrade to python 3.x will not break the world. Speaking of that let's get to the TODO TODO Upgrade to python 3.7 or above I believe will give us all the things we want. Use mocks in unittest once we have upgraded Change import scheme to python3 style (soooo much better) Update style for everything python3, including asyncio, generators/yield, import changes, etc... Test setup.py for machine not on same network as control system and generate mock/debug objects for testing Actually verify a requirements.txt file covers all dependencies Create a CLI tool Provide example application using lcls_tools Add more examples Document with sphinx (so boring, hoping someone else wants to do this) Make a robust and somewhat flexible logger module that knows about SLAC things, current logger is very basic Dependancies: See requirements.txt CAUTION: This is a POC, use at own risk. THESE TOOLS ARE IN VARIOUS STAGES OF DEVELOPMENT","title":"Home"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#about","text":"LCLS is in need of various tools to support high level application development using python. This is an effort to locate a single repo that can be referenced for developemnt.","title":"About"},{"location":"#lcls-tools","text":"Python tools for LCLS: * Device API (profile monitors, stoppers, magnets, etc...) * SLAC Logger * Custom Math Tools * Image Processing Tools * Beam calculations (emittance, solenoid alignment corrections, etc...)","title":"lcls-tools"},{"location":"#rules-of-contribution-and-python-coding-in-general","text":"Make your code readable (I like good one liners as much as the next person, but pulling apart syntax can be painful) Add comments whenever possible Try your best to adhere to style guidelines set forth in PEP8 Try to be idiomatic , there is a reason people spent time writing these guides. People are sick of seeing a simple operation being done a million different ways and having to parse out what insanity was behind some lines of code. Add tests (unittest is used currently, please use unit tests at a bare minimum) Focus on extensibility (don't shove a bunch of modules/classes into one file or directory and make them reference each other if you can avoid it) Try to understand the purpose of each tool and do not overcomplicate with business logic that can live in an application. These should be small and useful tools/apis with well understood and firm contracts between the api and the user Bonus: If you do all of the above in general, you will be a much better coder","title":"Rules of contribution (and python coding in general)"},{"location":"#why-python27","text":"Unfortunately, the control system LCLS uses has Python27 as a default. That means these tools need to be compatible. This is a compliation of code written by different people so it's not entirely uniform, but I believe an upgrade to python 3.x will not break the world. Speaking of that let's get to the TODO","title":"Why Python2.7"},{"location":"#todo","text":"Upgrade to python 3.7 or above I believe will give us all the things we want. Use mocks in unittest once we have upgraded Change import scheme to python3 style (soooo much better) Update style for everything python3, including asyncio, generators/yield, import changes, etc... Test setup.py for machine not on same network as control system and generate mock/debug objects for testing Actually verify a requirements.txt file covers all dependencies Create a CLI tool Provide example application using lcls_tools Add more examples Document with sphinx (so boring, hoping someone else wants to do this) Make a robust and somewhat flexible logger module that knows about SLAC things, current logger is very basic","title":"TODO"},{"location":"#dependancies-see-requirementstxt","text":"","title":"Dependancies: See requirements.txt"},{"location":"#caution-this-is-a-poc-use-at-own-risk-these-tools-are-in-various-stages-of-development","text":"","title":"CAUTION: This is a POC, use at own risk. THESE TOOLS ARE IN VARIOUS STAGES OF DEVELOPMENT"},{"location":"Correlation_Plot/","text":"Correlation Plot These tools are used to find a relationship between the size of the beam and the magnet strength. The sections below contains packages that are used to view and analyze the correlation plots as well as test if that code works correctly. How to view a Correlation Plot The purpose of this package is to unpack a .mat file and allow the examination of the correlation plots. The tool currently has hard coded paths specific to the author of the code and will need to be updated to suit anyone. This package may soon be available at GitHub.com . Useful Information Uses cor_plot tools from lcls-tools. Loads data and plots a correlation plot from the data. Error bars indicate the deviance from the mean at each x value. x values (magnet strength) are found using the tool ctrl_vals. At each x value, some number of iterations will be taken. A specific fit and beam name can be chosen from the following lists: FIT = ['Gaussian', 'Asymmetric', 'Super', 'RMS', 'RMS cut peak', 'RMS cut area', 'RMS floor'] beam_names: profx, xStat, profy, yStat, profu, uStat, stats In each iteration, some number of samples are taken. The mean of the samples in each iteration is taken and appended to a new array. This new array is used for the y values (beam size). The x array is plotted against the y array, along with error bars. Correlation Plot Analysis This utility, found here , can take a cor plot .mat file and turn it into a python data object. The goal is to present the data from a cor plot in a meaningful way. Below shows an example of the test that was used for theoriginal package. The full test can be found here . Example: 'test_scan.mat' Import and Initialize cor plot data object from cor_plot_mat_scan import CorPlotMatScan as CPMS cpms = CPMS('test_scan.mat') Access Properties. Here are some of the properties that are defined for the data object. cpms.fields ('accelerator', 'status', 'ctrlPV', 'beam', 'profPV', 'ts', 'config') >>> cpms.accelerator 'LCLS2' >>> cpms.ctrl_pv 'SOLN:GUNB:212:BCTRL' >>> cpms.iterations 10 >>> cpms.ctrl_vals [0.072999999999999995, 0.073888888888888879, 0.074777777777777776, 0.07566666666666666, 0.076555555555555557, 0.077444444444444441, 0.078333333333333338, 0.079222222222222222, 0.080111111111111119, 0.081000000000000003] >>> cpms.beam_names ('profx', 'xStat', 'xStatStd', 'profy', 'yStat', 'yStatStd', 'profu', 'uStat', 'uStatStd', 'method', 'stats', 'statsStd') >>> cpms.timestamp 737730.05017097027 >>> cpms.samples 2 Access Beam Data. This is very tricky and could use some cleanup. This is all the metadata associated with the scan and goes by the nature of cpms.beam[iteration][sample][fit]. The fits are in the following order FIT = ['Gaussian', 'Asymmetric', 'Super', 'RMS', 'RMS cut peak', 'RMS cut area', 'RMS floor']. Example, say I want to get a specific field from beam_names. Say 'profx' for iteration 3, sample 2 and 'RMS cut peak' (5, index of 4): >>> cpms.beam[2][1][4]['profx'] array([[ -8.04000000e+03, -8.02392000e+03, -8.00784000e+03, ..., 5.37072000e+03, 5.38680000e+03, 5.40288000e+03], [ 0.00000000e+00, 0.00000000e+00, 2.49000000e+02, ..., 1.72000000e+02, 0.00000000e+00, 2.64000000e+02], [ 1.72791308e+01, 1.77236486e+01, 1.81784282e+01, ..., 4.98085984e+00, 4.84116133e+00, 4.70507716e+00]]) Function uses >>> cpms.file Loads a .mat file >>> cpms.fields Shows different data fields >>> cpms.control_dict control PV and values, units, etc.. >>> cpms.accelerator Shows accelerator name >>> cpms.ctrl_pv Scans PV >>> cpms.iterations >>> cpms.ctrl_vals Values for control PV in scans >>> cpms.beam Unpacks the beam data >>> cpms.beam_names The different keys for a beam dict >>> cpms.timestamp Unpacks Matlab timestamp >>> cpms.config Random collection of data >>> cpms.samples Returns the length of the beam at index 0 >>> cpms.unpack... The remaining functions unpack the data in the .mat file Note As you can see, this whole beam property needs a lot of cleanup. I do not even know what profx is, maybe an x projection/histogram of the profile monitor? Your guess is as good as mine. Good luck!","title":"Correlation plot"},{"location":"Correlation_Plot/#correlation-plot","text":"These tools are used to find a relationship between the size of the beam and the magnet strength. The sections below contains packages that are used to view and analyze the correlation plots as well as test if that code works correctly.","title":"Correlation Plot"},{"location":"Correlation_Plot/#how-to-view-a-correlation-plot","text":"The purpose of this package is to unpack a .mat file and allow the examination of the correlation plots. The tool currently has hard coded paths specific to the author of the code and will need to be updated to suit anyone. This package may soon be available at GitHub.com .","title":"How to view a Correlation Plot"},{"location":"Correlation_Plot/#useful-information","text":"Uses cor_plot tools from lcls-tools. Loads data and plots a correlation plot from the data. Error bars indicate the deviance from the mean at each x value. x values (magnet strength) are found using the tool ctrl_vals. At each x value, some number of iterations will be taken. A specific fit and beam name can be chosen from the following lists: FIT = ['Gaussian', 'Asymmetric', 'Super', 'RMS', 'RMS cut peak', 'RMS cut area', 'RMS floor'] beam_names: profx, xStat, profy, yStat, profu, uStat, stats In each iteration, some number of samples are taken. The mean of the samples in each iteration is taken and appended to a new array. This new array is used for the y values (beam size). The x array is plotted against the y array, along with error bars.","title":"Useful Information"},{"location":"Correlation_Plot/#correlation-plot-analysis","text":"This utility, found here , can take a cor plot .mat file and turn it into a python data object. The goal is to present the data from a cor plot in a meaningful way. Below shows an example of the test that was used for theoriginal package. The full test can be found here . Example: 'test_scan.mat' Import and Initialize cor plot data object from cor_plot_mat_scan import CorPlotMatScan as CPMS cpms = CPMS('test_scan.mat') Access Properties. Here are some of the properties that are defined for the data object. cpms.fields ('accelerator', 'status', 'ctrlPV', 'beam', 'profPV', 'ts', 'config') >>> cpms.accelerator 'LCLS2' >>> cpms.ctrl_pv 'SOLN:GUNB:212:BCTRL' >>> cpms.iterations 10 >>> cpms.ctrl_vals [0.072999999999999995, 0.073888888888888879, 0.074777777777777776, 0.07566666666666666, 0.076555555555555557, 0.077444444444444441, 0.078333333333333338, 0.079222222222222222, 0.080111111111111119, 0.081000000000000003] >>> cpms.beam_names ('profx', 'xStat', 'xStatStd', 'profy', 'yStat', 'yStatStd', 'profu', 'uStat', 'uStatStd', 'method', 'stats', 'statsStd') >>> cpms.timestamp 737730.05017097027 >>> cpms.samples 2 Access Beam Data. This is very tricky and could use some cleanup. This is all the metadata associated with the scan and goes by the nature of cpms.beam[iteration][sample][fit]. The fits are in the following order FIT = ['Gaussian', 'Asymmetric', 'Super', 'RMS', 'RMS cut peak', 'RMS cut area', 'RMS floor']. Example, say I want to get a specific field from beam_names. Say 'profx' for iteration 3, sample 2 and 'RMS cut peak' (5, index of 4): >>> cpms.beam[2][1][4]['profx'] array([[ -8.04000000e+03, -8.02392000e+03, -8.00784000e+03, ..., 5.37072000e+03, 5.38680000e+03, 5.40288000e+03], [ 0.00000000e+00, 0.00000000e+00, 2.49000000e+02, ..., 1.72000000e+02, 0.00000000e+00, 2.64000000e+02], [ 1.72791308e+01, 1.77236486e+01, 1.81784282e+01, ..., 4.98085984e+00, 4.84116133e+00, 4.70507716e+00]])","title":"Correlation Plot Analysis"},{"location":"Correlation_Plot/#function-uses","text":">>> cpms.file Loads a .mat file >>> cpms.fields Shows different data fields >>> cpms.control_dict control PV and values, units, etc.. >>> cpms.accelerator Shows accelerator name >>> cpms.ctrl_pv Scans PV >>> cpms.iterations >>> cpms.ctrl_vals Values for control PV in scans >>> cpms.beam Unpacks the beam data >>> cpms.beam_names The different keys for a beam dict >>> cpms.timestamp Unpacks Matlab timestamp >>> cpms.config Random collection of data >>> cpms.samples Returns the length of the beam at index 0 >>> cpms.unpack... The remaining functions unpack the data in the .mat file","title":"Function uses"},{"location":"Correlation_Plot/#note","text":"As you can see, this whole beam property needs a lot of cleanup. I do not even know what profx is, maybe an x projection/histogram of the profile monitor? Your guess is as good as mine. Good luck!","title":"Note"},{"location":"Data_Analysis/","text":"Data Analysis Archiver The data analysis package consists of the archiver utility and its associated test. The goal of the data Archiver utility is to provide functions that assist in converting data into python objects and storing that data in H5 files. This utility is found here . Initializations and imports >>> from datetime import datetime, timedelta >>> import meme.archive >>> import meme.names >>> from mat_image import MatImage as MI mi = MI() The following explains how the functions in the Archiver are used. >>> arch.datenum_to_datetime(datenum) Converts Matlab datenum into Python datetime. This is helpful to analyze the data. >>> arch.get_iso_time(pytime) This will format iso time from python datetime. >>> arch.save_mat_image_attributes(mi,h5) Attempts to save .mat image attributes to an h5 file. >>> arch.save_image_to_h5(mi, h5group) Saves .mat image and meta data to h5 file. The data is seperated by timestamp, which is converted from matlab datnum to python datetime. mi -- matlab image object h5group -- h5 group or dataset to save attributes >>> arch.save_pvdata_to_h5 This function will save pvdata at specific isotime to h5 file. The utility is currently under development. Archiver test This utility will test the functions in the Archiver package to ensure that the package will complete it's intended purpose. The full test can be found here .","title":"Data Analysis"},{"location":"Data_Analysis/#data-analysis","text":"","title":"Data Analysis"},{"location":"Data_Analysis/#archiver","text":"The data analysis package consists of the archiver utility and its associated test. The goal of the data Archiver utility is to provide functions that assist in converting data into python objects and storing that data in H5 files. This utility is found here . Initializations and imports >>> from datetime import datetime, timedelta >>> import meme.archive >>> import meme.names >>> from mat_image import MatImage as MI mi = MI() The following explains how the functions in the Archiver are used. >>> arch.datenum_to_datetime(datenum) Converts Matlab datenum into Python datetime. This is helpful to analyze the data. >>> arch.get_iso_time(pytime) This will format iso time from python datetime. >>> arch.save_mat_image_attributes(mi,h5) Attempts to save .mat image attributes to an h5 file. >>> arch.save_image_to_h5(mi, h5group) Saves .mat image and meta data to h5 file. The data is seperated by timestamp, which is converted from matlab datnum to python datetime. mi -- matlab image object h5group -- h5 group or dataset to save attributes >>> arch.save_pvdata_to_h5 This function will save pvdata at specific isotime to h5 file. The utility is currently under development.","title":"Archiver"},{"location":"Data_Analysis/#archiver-test","text":"This utility will test the functions in the Archiver package to ensure that the package will complete it's intended purpose. The full test can be found here .","title":"Archiver test"},{"location":"Devices/","text":"Devices The devices in this package consist of the magnet and the profile monitor.","title":"Devices"},{"location":"Devices/#devices","text":"The devices in this package consist of the magnet and the profile monitor.","title":"Devices"},{"location":"Emittance_Scan/","text":"Emittance Scan Emittance Scan Analysis This utility can take an emittance scan .mat file and turn it into a python data object. The goal is to present the data from an emittance scan in a meaningful way. This utility has a test file can be used as an example. The full test is at the link above. Example: 'test_scan.mat' Import and Initialize emit scan data object >>> from mat_emit_scan import MatEmitScan as MES >>> mes = MES('test_scan.mat') Look at some metadata provided >>> mes.fields ('status', 'type', 'name', 'quadName', 'quadVal', 'use', 'ts', 'beam', 'beamStd', 'beamList', 'chargeList', 'charge', 'chargeStd', 'rMatrix', 'twiss0', 'energy', 'twiss', 'twissstd', 'orbit', 'orbitstd', 'twissPV') >>> mes.mat_file 'test_scan.mat' >>> mes.status [1, 1, 1, 1, 1, 1, 1, 1, 1, 1] >>> mes.scan_type 'scan' >>> mes.name 'YAGS:GUNB:753' >>> mes.quad_name 'SOLN:GUNB:212' >>> mes.quad_vals array([ 0.072 , 0.07288889, 0.07377778, 0.07466667, 0.07555556, 0.07644444, 0.07733333, 0.07822222, 0.07911111, 0.08 ]) >>> mes.energy 0.00080999999999999996 >>> mes.emit_x {'RMS': 3.4515596891751565, 'RMS floor': 9.7058411460479448, 'Asymmetric': 2.3011730612686216, 'RMS cut peak': 4.1500304671227708, 'Gaussian': 2.2849066179125792, 'RMS cut area': 2.4536073194623635, 'Super': 1.688336458977292} >>> mes.beta_x {'RMS': 80.484605665606026, 'RMS floor': 100.91535950661032, 'Asymmetric': 97.804316246866463, 'RMS cut peak': 76.108952766218465, 'Gaussian': 96.099462789374726, 'RMS cut area': 99.545334166075449, 'Super': 93.171709901593815} >>> mes.alpha_x {'RMS': -55.395171987314683, 'RMS floor': -69.88573148701731, 'Asymmetric': -67.660687952024801, 'RMS cut peak': -52.608008222157309, 'Gaussian': -66.480550801923854, 'RMS cut area': -68.518659896328131, 'Super': -64.492473842048952} >>> mes.bmag_x {'RMS': 1007.7399628928547, 'RMS floor': 1268.6334422248324, 'Asymmetric': 1228.6852675287346, 'RMS cut peak': 955.62547016282565, 'Gaussian': 1207.2601105065046, 'RMS cut area': 1246.4364849169979, 'Super': 1170.9257736052093} There are more properties, but it's tough to list them all here. Read the code to see all avialable properties until documentation is being written. Hoping someone can sphinx this stuff. Now for the beam property. This is a bit disconcerting as in a cor plot scan, the beam property contains samples, but here it only seems to have one available sample (no list nesting). Anyway, in this case it seems to be mes.beam[iteration][fit], where fit is the same FIT = ['Gaussian', 'Asymmetric', 'Super', 'RMS', 'RMS cut peak', 'RMS cut area', 'RMS floor']. So in an example, say I want the 'profx' data for the 'Super' fit (index 2) for iteration 2 (index 1). >>> mes.beam[1][2]['profx'] array([[-6737.52 , -6721.44 , -6705.36 , ..., 2942.64 , 2958.72 , 2974.8 ], [ 164. , 15. , 77. , ..., -52. , 163. , 84. ], [ 19.07582407, 19.07582407, 19.07582407, ..., 19.07582407, 19.07582407, 19.07582407]]) We could find out that this beam structure is actually similar to how it is in the cor plot .mat scan. Then we could use the same unpacking function here in emittance scan (or define a general factory method). I leave that up to further validation, and maybe we can have a summer student work on that. Example: 'test_scan.mat' Import and Initialize emit scan data object >>> from mat_emit_scan import MatEmitScan as MES >>> mes = MES('test_scan.mat') Look at some metadata provided >>> mes.fields ('status', 'type', 'name', 'quadName', 'quadVal', 'use', 'ts', 'beam', 'beamStd', 'beamList', 'chargeList', 'charge', 'chargeStd', 'rMatrix', 'twiss0', 'energy', 'twiss', 'twissstd', 'orbit', 'orbitstd', 'twissPV') >>> mes.mat_file 'test_scan.mat' >>> mes.status [1, 1, 1, 1, 1, 1, 1, 1, 1, 1] >>> mes.scan_type 'scan' >>> mes.name 'YAGS:GUNB:753' >>> mes.quad_name 'SOLN:GUNB:212' >>> mes.quad_vals array([ 0.072 , 0.07288889, 0.07377778, 0.07466667, 0.07555556, 0.07644444, 0.07733333, 0.07822222, 0.07911111, 0.08 ]) >>> mes.energy 0.00080999999999999996 >>> mes.emit_x {'RMS': 3.4515596891751565, 'RMS floor': 9.7058411460479448, 'Asymmetric': 2.3011730612686216, 'RMS cut peak': 4.1500304671227708, 'Gaussian': 2.2849066179125792, 'RMS cut area': 2.4536073194623635, 'Super': 1.688336458977292} >>> mes.beta_x {'RMS': 80.484605665606026, 'RMS floor': 100.91535950661032, 'Asymmetric': 97.804316246866463, 'RMS cut peak': 76.108952766218465, 'Gaussian': 96.099462789374726, 'RMS cut area': 99.545334166075449, 'Super': 93.171709901593815} >>> mes.alpha_x {'RMS': -55.395171987314683, 'RMS floor': -69.88573148701731, 'Asymmetric': -67.660687952024801, 'RMS cut peak': -52.608008222157309, 'Gaussian': -66.480550801923854, 'RMS cut area': -68.518659896328131, 'Super': -64.492473842048952} >>> mes.bmag_x {'RMS': 1007.7399628928547, 'RMS floor': 1268.6334422248324, 'Asymmetric': 1228.6852675287346, 'RMS cut peak': 955.62547016282565, 'Gaussian': 1207.2601105065046, 'RMS cut area': 1246.4364849169979, 'Super': 1170.9257736052093} There are more properties, but it's tough to list them all here. Read the code to see all avialable properties until documentation is being written. Hoping someone can sphinx this stuff. Now for the beam property. This is a bit disconcerting as in a cor plot scan, the beam property contains samples, but here it only seems to have one available sample (no list nesting). Anyway, in this case it seems to be mes.beam[iteration][fit], where fit is the same FIT = ['Gaussian', 'Asymmetric', 'Super', 'RMS', 'RMS cut peak', 'RMS cut area', 'RMS floor']. So in an example, say I want the 'profx' data for the 'Super' fit (index 2) for iteration 2 (index 1). >>> mes.beam[1][2]['profx'] array([[-6737.52 , -6721.44 , -6705.36 , ..., 2942.64 , 2958.72 , 2974.8 ], [ 164. , 15. , 77. , ..., -52. , 163. , 84. ], [ 19.07582407, 19.07582407, 19.07582407, ..., 19.07582407, 19.07582407, 19.07582407]]) Note We could find out that this beam structure is actually similar to how it is in the cor plot .mat scan. Then we could use the same unpacking function here in emittance scan (or define a general factory method). I leave that up to further validation.","title":"Emittance Scan"},{"location":"Emittance_Scan/#emittance-scan","text":"","title":"Emittance Scan"},{"location":"Emittance_Scan/#emittance-scan-analysis","text":"This utility can take an emittance scan .mat file and turn it into a python data object. The goal is to present the data from an emittance scan in a meaningful way. This utility has a test file can be used as an example. The full test is at the link above. Example: 'test_scan.mat' Import and Initialize emit scan data object >>> from mat_emit_scan import MatEmitScan as MES >>> mes = MES('test_scan.mat') Look at some metadata provided >>> mes.fields ('status', 'type', 'name', 'quadName', 'quadVal', 'use', 'ts', 'beam', 'beamStd', 'beamList', 'chargeList', 'charge', 'chargeStd', 'rMatrix', 'twiss0', 'energy', 'twiss', 'twissstd', 'orbit', 'orbitstd', 'twissPV') >>> mes.mat_file 'test_scan.mat' >>> mes.status [1, 1, 1, 1, 1, 1, 1, 1, 1, 1] >>> mes.scan_type 'scan' >>> mes.name 'YAGS:GUNB:753' >>> mes.quad_name 'SOLN:GUNB:212' >>> mes.quad_vals array([ 0.072 , 0.07288889, 0.07377778, 0.07466667, 0.07555556, 0.07644444, 0.07733333, 0.07822222, 0.07911111, 0.08 ]) >>> mes.energy 0.00080999999999999996 >>> mes.emit_x {'RMS': 3.4515596891751565, 'RMS floor': 9.7058411460479448, 'Asymmetric': 2.3011730612686216, 'RMS cut peak': 4.1500304671227708, 'Gaussian': 2.2849066179125792, 'RMS cut area': 2.4536073194623635, 'Super': 1.688336458977292} >>> mes.beta_x {'RMS': 80.484605665606026, 'RMS floor': 100.91535950661032, 'Asymmetric': 97.804316246866463, 'RMS cut peak': 76.108952766218465, 'Gaussian': 96.099462789374726, 'RMS cut area': 99.545334166075449, 'Super': 93.171709901593815} >>> mes.alpha_x {'RMS': -55.395171987314683, 'RMS floor': -69.88573148701731, 'Asymmetric': -67.660687952024801, 'RMS cut peak': -52.608008222157309, 'Gaussian': -66.480550801923854, 'RMS cut area': -68.518659896328131, 'Super': -64.492473842048952} >>> mes.bmag_x {'RMS': 1007.7399628928547, 'RMS floor': 1268.6334422248324, 'Asymmetric': 1228.6852675287346, 'RMS cut peak': 955.62547016282565, 'Gaussian': 1207.2601105065046, 'RMS cut area': 1246.4364849169979, 'Super': 1170.9257736052093} There are more properties, but it's tough to list them all here. Read the code to see all avialable properties until documentation is being written. Hoping someone can sphinx this stuff. Now for the beam property. This is a bit disconcerting as in a cor plot scan, the beam property contains samples, but here it only seems to have one available sample (no list nesting). Anyway, in this case it seems to be mes.beam[iteration][fit], where fit is the same FIT = ['Gaussian', 'Asymmetric', 'Super', 'RMS', 'RMS cut peak', 'RMS cut area', 'RMS floor']. So in an example, say I want the 'profx' data for the 'Super' fit (index 2) for iteration 2 (index 1). >>> mes.beam[1][2]['profx'] array([[-6737.52 , -6721.44 , -6705.36 , ..., 2942.64 , 2958.72 , 2974.8 ], [ 164. , 15. , 77. , ..., -52. , 163. , 84. ], [ 19.07582407, 19.07582407, 19.07582407, ..., 19.07582407, 19.07582407, 19.07582407]]) We could find out that this beam structure is actually similar to how it is in the cor plot .mat scan. Then we could use the same unpacking function here in emittance scan (or define a general factory method). I leave that up to further validation, and maybe we can have a summer student work on that. Example: 'test_scan.mat' Import and Initialize emit scan data object >>> from mat_emit_scan import MatEmitScan as MES >>> mes = MES('test_scan.mat') Look at some metadata provided >>> mes.fields ('status', 'type', 'name', 'quadName', 'quadVal', 'use', 'ts', 'beam', 'beamStd', 'beamList', 'chargeList', 'charge', 'chargeStd', 'rMatrix', 'twiss0', 'energy', 'twiss', 'twissstd', 'orbit', 'orbitstd', 'twissPV') >>> mes.mat_file 'test_scan.mat' >>> mes.status [1, 1, 1, 1, 1, 1, 1, 1, 1, 1] >>> mes.scan_type 'scan' >>> mes.name 'YAGS:GUNB:753' >>> mes.quad_name 'SOLN:GUNB:212' >>> mes.quad_vals array([ 0.072 , 0.07288889, 0.07377778, 0.07466667, 0.07555556, 0.07644444, 0.07733333, 0.07822222, 0.07911111, 0.08 ]) >>> mes.energy 0.00080999999999999996 >>> mes.emit_x {'RMS': 3.4515596891751565, 'RMS floor': 9.7058411460479448, 'Asymmetric': 2.3011730612686216, 'RMS cut peak': 4.1500304671227708, 'Gaussian': 2.2849066179125792, 'RMS cut area': 2.4536073194623635, 'Super': 1.688336458977292} >>> mes.beta_x {'RMS': 80.484605665606026, 'RMS floor': 100.91535950661032, 'Asymmetric': 97.804316246866463, 'RMS cut peak': 76.108952766218465, 'Gaussian': 96.099462789374726, 'RMS cut area': 99.545334166075449, 'Super': 93.171709901593815} >>> mes.alpha_x {'RMS': -55.395171987314683, 'RMS floor': -69.88573148701731, 'Asymmetric': -67.660687952024801, 'RMS cut peak': -52.608008222157309, 'Gaussian': -66.480550801923854, 'RMS cut area': -68.518659896328131, 'Super': -64.492473842048952} >>> mes.bmag_x {'RMS': 1007.7399628928547, 'RMS floor': 1268.6334422248324, 'Asymmetric': 1228.6852675287346, 'RMS cut peak': 955.62547016282565, 'Gaussian': 1207.2601105065046, 'RMS cut area': 1246.4364849169979, 'Super': 1170.9257736052093} There are more properties, but it's tough to list them all here. Read the code to see all avialable properties until documentation is being written. Hoping someone can sphinx this stuff. Now for the beam property. This is a bit disconcerting as in a cor plot scan, the beam property contains samples, but here it only seems to have one available sample (no list nesting). Anyway, in this case it seems to be mes.beam[iteration][fit], where fit is the same FIT = ['Gaussian', 'Asymmetric', 'Super', 'RMS', 'RMS cut peak', 'RMS cut area', 'RMS floor']. So in an example, say I want the 'profx' data for the 'Super' fit (index 2) for iteration 2 (index 1). >>> mes.beam[1][2]['profx'] array([[-6737.52 , -6721.44 , -6705.36 , ..., 2942.64 , 2958.72 , 2974.8 ], [ 164. , 15. , 77. , ..., -52. , 163. , 84. ], [ 19.07582407, 19.07582407, 19.07582407, ..., 19.07582407, 19.07582407, 19.07582407]])","title":"Emittance Scan Analysis"},{"location":"Emittance_Scan/#note","text":"We could find out that this beam structure is actually similar to how it is in the cor plot .mat scan. Then we could use the same unpacking function here in emittance scan (or define a general factory method). I leave that up to further validation.","title":"Note"},{"location":"Image_Processing/","text":"Image Processing Package The Image Processing package takes an electron beam image .mat file and turns it into a python data object. The goal of this package is to analyze and describe an electron beam image, which allows a glimps into the size of the beam and also can be used to calculate the emittance. This package contains several utilities that are essential to the image processing utility. They are as follows: fit_gaussian.py This utility reads in a matlab file of xcor data and fits gaussians to it. image.py Defines the functions that turn the image into a python object. mat_image.py Creates a .mat image object from a typical LCLS .mat file. Image Processing Utility The image processing utility has several functions that can be used to analyze the electron beam images. This utility can be found here . Initialization and import usage: >>> Utility imports Below is a list of the imports required to run the utility: import numpy as np import scipy.ndimage as snd from scipy.optimize import curve_fit from scipy import asarray import matplotlib.pyplot as plt import fit_gaussian as fg from time import time To use the utility, install the package and import image_processing.py as ip Function Use The following explains how to use the functions in the utility. >>> ip.fliplr(image) Flips the image over the vertical axis. >>> ip.flipup(image) Flips the image over the horizontal axis. >>> ip.center_of_mass(image, sigma=5) Finds the center of mass of the image by calculating the mean the image's pixels and adding that to the sigma multiplied to standard deviation of the image's pixels. >>> ip.average_image(images) Finds the average number of images. >>> ip.shape_image(image, x_size, y_size) Shapes the size of the image by rewriting the array. >>> ip.x_projection(image, axis=0, subtract_baseline=true) Expects an ndarray and returns an x projection. Sums up all the elements in the array at axis = 0. >>> ip.y_projection(image, subtract_baseline=true) Returns y projection. >>> ip.gauss_func Calculates the gaussian function for the image. >>> ip.gauss_fit Calculates the best gaussian fit for the image array. Each utility has a test associated with it that is meant to check that each function is","title":"Image Processing"},{"location":"Image_Processing/#image-processing-package","text":"The Image Processing package takes an electron beam image .mat file and turns it into a python data object. The goal of this package is to analyze and describe an electron beam image, which allows a glimps into the size of the beam and also can be used to calculate the emittance. This package contains several utilities that are essential to the image processing utility. They are as follows: fit_gaussian.py This utility reads in a matlab file of xcor data and fits gaussians to it. image.py Defines the functions that turn the image into a python object. mat_image.py Creates a .mat image object from a typical LCLS .mat file.","title":"Image Processing Package"},{"location":"Image_Processing/#image-processing-utility","text":"The image processing utility has several functions that can be used to analyze the electron beam images. This utility can be found here . Initialization and import usage: >>> Utility imports Below is a list of the imports required to run the utility: import numpy as np import scipy.ndimage as snd from scipy.optimize import curve_fit from scipy import asarray import matplotlib.pyplot as plt import fit_gaussian as fg from time import time To use the utility, install the package and import image_processing.py as ip","title":"Image Processing Utility"},{"location":"Image_Processing/#function-use","text":"The following explains how to use the functions in the utility. >>> ip.fliplr(image) Flips the image over the vertical axis. >>> ip.flipup(image) Flips the image over the horizontal axis. >>> ip.center_of_mass(image, sigma=5) Finds the center of mass of the image by calculating the mean the image's pixels and adding that to the sigma multiplied to standard deviation of the image's pixels. >>> ip.average_image(images) Finds the average number of images. >>> ip.shape_image(image, x_size, y_size) Shapes the size of the image by rewriting the array. >>> ip.x_projection(image, axis=0, subtract_baseline=true) Expects an ndarray and returns an x projection. Sums up all the elements in the array at axis = 0. >>> ip.y_projection(image, subtract_baseline=true) Returns y projection. >>> ip.gauss_func Calculates the gaussian function for the image. >>> ip.gauss_fit Calculates the best gaussian fit for the image array. Each utility has a test associated with it that is meant to check that each function is","title":"Function Use"},{"location":"Logger/","text":"Logger","title":"Logger"},{"location":"Logger/#logger","text":"","title":"Logger"},{"location":"Math_Tools/","text":"Math Tools About","title":"Math Tools"},{"location":"Math_Tools/#math-tools","text":"","title":"Math Tools"},{"location":"Math_Tools/#about","text":"","title":"About"},{"location":"Solenoid_Calculation/","text":"Beam Calculations The Solenoid is a lense inside the LCLS that is used to correct the momentum of the individual electrons that compose the electron beam. This is crucial to maintaining the size and shape of the beam. Solenoid Calculation Package The goal of this utility is to collect data from the electron beam as it passes through the solenoid and use that data to calculate the best position of the solenoid for what is needed. This package, found here , is currently under development. Import and Initialize Solenoid calc. data object >>> from sol_calc import SolCalc as S >>> s = S(0.05, 0.5, 0.1) Function uses: >>> s.x_vals [] >>> s.y_vals [] >>> s.x_stds [] >>> s.y_stds [] >>> s.b_vals [] >>> s.results none >>> s.gun_energy e_gun, .5 >>> s.length l, .05 >>> s.calc_p momentum calculation gamma = 1.0 + (self._e_gun / 0.511) beta = sqrt(1.0 - (1/gamma)**2) return beta*gamma*sc.m_e*sc.c >>> s.calc_K Get the current K value return (b * sc.e) / (2*p) The remaining functions are calculations that will be used to generate an x and y array. The final function will then use the arrays to offset the previous solenoid calculation. Solenoid Calculation Test This utility will test the functions in the solenoid calculation package to ensure that the package will complete it's intended purpose. The full test can be found here More packages to come.","title":"Beam Calculations"},{"location":"Solenoid_Calculation/#beam-calculations","text":"The Solenoid is a lense inside the LCLS that is used to correct the momentum of the individual electrons that compose the electron beam. This is crucial to maintaining the size and shape of the beam.","title":"Beam Calculations"},{"location":"Solenoid_Calculation/#solenoid-calculation-package","text":"The goal of this utility is to collect data from the electron beam as it passes through the solenoid and use that data to calculate the best position of the solenoid for what is needed. This package, found here , is currently under development. Import and Initialize Solenoid calc. data object >>> from sol_calc import SolCalc as S >>> s = S(0.05, 0.5, 0.1) Function uses: >>> s.x_vals [] >>> s.y_vals [] >>> s.x_stds [] >>> s.y_stds [] >>> s.b_vals [] >>> s.results none >>> s.gun_energy e_gun, .5 >>> s.length l, .05 >>> s.calc_p momentum calculation gamma = 1.0 + (self._e_gun / 0.511) beta = sqrt(1.0 - (1/gamma)**2) return beta*gamma*sc.m_e*sc.c >>> s.calc_K Get the current K value return (b * sc.e) / (2*p) The remaining functions are calculations that will be used to generate an x and y array. The final function will then use the arrays to offset the previous solenoid calculation.","title":"Solenoid Calculation Package"},{"location":"Solenoid_Calculation/#solenoid-calculation-test","text":"This utility will test the functions in the solenoid calculation package to ensure that the package will complete it's intended purpose. The full test can be found here More packages to come.","title":"Solenoid Calculation Test"}]}